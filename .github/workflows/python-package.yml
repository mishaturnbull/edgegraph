on:
  push:
    branches: [ "master", "develop", "release/*" ]
  pull_request:
    branches: [ "master", "develop" ]

jobs:
  build:

    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        # check on all non-end-of-life python versions
        python-version: ["3.7", "3.8", "3.9", "3.10", "3.11", "3.12"]

    steps:
    # get everything set up
    - uses: actions/checkout@main
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@main
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install dependencies
      run: |
        sudo apt update
        sudo apt install plantuml
        python -m pip install --upgrade pip
        pip install -r scripts/test-requirements.txt
        pip install -r scripts/docs-requirements.txt

    - name: Documentation coverage
      if: ${{ matrix.python-version == '3.12' }}
      run: |
        cd docs
        make coverage
        cat _build/coverage/python.txt
        if [[ ( $(grep TOTAL _build/coverage/python.txt | awk '{print $4}') == "100.00%") ]]; then true; else false; fi

    - name: Pylint check
      run: |
        # pylintrc equivalent (in pyproject.toml) takes care of the options
        # here, no need to cli-flag everything
        pylint --exit-zero edgegraph tests

    - name: Black format check
      # there's only sense in running black against the latest version.  it's
      # the same code no matter what, and black performs the same analysis
      # (except on py3.7, which predates black reading from pyproject.toml and
      # missing some configs)
      if: ${{ matrix.python-version == '3.12' }}
      run: |
        black --check edgegraph tests docs

    - name: Run unit tests
      run: |
        # this does generate the code coverage report.  however, pytest-cov
        # plugin seems can't cause it to exit nonzero on a "not enough coverage"
        # condition... so we'll just save off the coverage info here, and check
        # it in the next step.
        #
        # we also collect the longest handful of unit test durations here --
        # mainly for trend detection, to see if "oh hey, this particular test
        # is always slow".  nothing is programmatically using the data, at
        # least, yet.  but, don't run the marked-as-slow stress tests here to
        # avoid taking up too much time on the runner (of concern due to
        # GitHub's pricing)
        pytest --cov=edgegraph --cov-branch --durations=0 -m "not (slow or perf)"

    - name: Check unit test coverage
      run: |
        # fail-under option causes a nonzero exit
        coverage report --fail-under=100

